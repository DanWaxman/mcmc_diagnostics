<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Michael Betancourt">
<meta name="dcterms.date" content="2022-11-01">

<title>Markov Chain Monte Carlo Diagnostics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="mcmc_diagnostics_pystan2_files/libs/clipboard/clipboard.min.js"></script>
<script src="mcmc_diagnostics_pystan2_files/libs/quarto-html/quarto.js"></script>
<script src="mcmc_diagnostics_pystan2_files/libs/quarto-html/popper.min.js"></script>
<script src="mcmc_diagnostics_pystan2_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="mcmc_diagnostics_pystan2_files/libs/quarto-html/anchor.min.js"></script>
<link href="mcmc_diagnostics_pystan2_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="mcmc_diagnostics_pystan2_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="mcmc_diagnostics_pystan2_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="mcmc_diagnostics_pystan2_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="mcmc_diagnostics_pystan2_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#hamiltonian-monte-carlo-diagnostics" id="toc-hamiltonian-monte-carlo-diagnostics" class="nav-link active" data-scroll-target="#hamiltonian-monte-carlo-diagnostics"><span class="toc-section-number">1</span>  Hamiltonian Monte Carlo Diagnostics</a>
  <ul class="collapse">
  <li><a href="#check-hamiltonian-monte-carlo-diagnostics" id="toc-check-hamiltonian-monte-carlo-diagnostics" class="nav-link" data-scroll-target="#check-hamiltonian-monte-carlo-diagnostics"><span class="toc-section-number">1.1</span>  Check Hamiltonian Monte Carlo Diagnostics</a></li>
  <li><a href="#integrator-inverse-metric-elements" id="toc-integrator-inverse-metric-elements" class="nav-link" data-scroll-target="#integrator-inverse-metric-elements"><span class="toc-section-number">1.2</span>  Integrator Inverse Metric Elements</a></li>
  <li><a href="#integrator-step-sizes" id="toc-integrator-step-sizes" class="nav-link" data-scroll-target="#integrator-step-sizes"><span class="toc-section-number">1.3</span>  Integrator Step Sizes</a></li>
  <li><a href="#numerical-trajectory-lengths" id="toc-numerical-trajectory-lengths" class="nav-link" data-scroll-target="#numerical-trajectory-lengths"><span class="toc-section-number">1.4</span>  Numerical Trajectory Lengths</a></li>
  <li><a href="#average-proxy-acceptance-statistic" id="toc-average-proxy-acceptance-statistic" class="nav-link" data-scroll-target="#average-proxy-acceptance-statistic"><span class="toc-section-number">1.5</span>  Average Proxy Acceptance Statistic</a></li>
  <li><a href="#divergence-labeled-pairs-plot" id="toc-divergence-labeled-pairs-plot" class="nav-link" data-scroll-target="#divergence-labeled-pairs-plot"><span class="toc-section-number">1.6</span>  Divergence-Labeled Pairs Plot</a></li>
  </ul></li>
  <li><a href="#expectand-diagnostic-functions" id="toc-expectand-diagnostic-functions" class="nav-link" data-scroll-target="#expectand-diagnostic-functions"><span class="toc-section-number">2</span>  Expectand Diagnostic Functions</a>
  <ul class="collapse">
  <li><a href="#khat" id="toc-khat" class="nav-link" data-scroll-target="#khat"><span class="toc-section-number">2.1</span>  khat</a></li>
  <li><a href="#frozen-chains" id="toc-frozen-chains" class="nav-link" data-scroll-target="#frozen-chains"><span class="toc-section-number">2.2</span>  Frozen Chains</a></li>
  <li><a href="#split-rhat" id="toc-split-rhat" class="nav-link" data-scroll-target="#split-rhat"><span class="toc-section-number">2.3</span>  Split Rhat</a></li>
  <li><a href="#integrated-autocorrelation-time" id="toc-integrated-autocorrelation-time" class="nav-link" data-scroll-target="#integrated-autocorrelation-time"><span class="toc-section-number">2.4</span>  Integrated Autocorrelation Time</a></li>
  <li><a href="#all-expectand-diagnostics" id="toc-all-expectand-diagnostics" class="nav-link" data-scroll-target="#all-expectand-diagnostics"><span class="toc-section-number">2.5</span>  All Expectand Diagnostics</a></li>
  <li><a href="#empirical-autocorrelation-visualization" id="toc-empirical-autocorrelation-visualization" class="nav-link" data-scroll-target="#empirical-autocorrelation-visualization"><span class="toc-section-number">2.6</span>  Empirical Autocorrelation Visualization</a></li>
  <li><a href="#chain-separated-pairs-plot" id="toc-chain-separated-pairs-plot" class="nav-link" data-scroll-target="#chain-separated-pairs-plot"><span class="toc-section-number">2.7</span>  Chain-Separated Pairs Plot</a></li>
  </ul></li>
  <li><a href="#markov-chain-monte-carlo-estimation" id="toc-markov-chain-monte-carlo-estimation" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-estimation"><span class="toc-section-number">3</span>  Markov chain Monte Carlo Estimation</a></li>
  <li><a href="#demonstration" id="toc-demonstration" class="nav-link" data-scroll-target="#demonstration"><span class="toc-section-number">4</span>  Demonstration</a></li>
  <li><a href="#license" id="toc-license" class="nav-link" data-scroll-target="#license">License</a></li>
  <li><a href="#original-computing-environment" id="toc-original-computing-environment" class="nav-link" data-scroll-target="#original-computing-environment">Original Computing Environment</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Markov Chain Monte Carlo Diagnostics</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Michael Betancourt </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 1, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>In this short note I will preview the new suite of Markov chain Monte Carlo analysis tools that I will be introducing more formally in upcoming writing. These tools largely focus on diagnostics but there are also a few that cover Markov chain Monte Carlo estimation assuming a central limit theorem.</p>
<p>We’ll start with diagnostics specific to Hamiltonian Monte Carlo then consider more generic diagnostics that consider each expectand of interest one at a time. Finally we’ll look at a way to visualize one-dimensional pushforward distributions using Markov chain Monte Carlo to estimate bin probabilities.</p>
<p>Before any of that, however, we need to set up our graphics.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plot</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>plot.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> [<span class="dv">6</span>, <span class="dv">4</span>]</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>plot.rcParams[<span class="st">'figure.dpi'</span>] <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>plot.rcParams[<span class="st">'font.family'</span>] <span class="op">=</span> <span class="st">"Serif"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> LinearSegmentedColormap</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>light<span class="op">=</span><span class="st">"#DCBCBC"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>light_highlight<span class="op">=</span><span class="st">"#C79999"</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>mid<span class="op">=</span><span class="st">"#B97C7C"</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>mid_highlight<span class="op">=</span><span class="st">"#A25050"</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>dark<span class="op">=</span><span class="st">"#8F2727"</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>dark_highlight<span class="op">=</span><span class="st">"#7C0000"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>At the same time let’s introduce a helper function to cache Stan executables.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> multiprocessing</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>multiprocessing.set_start_method(<span class="st">"fork"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pystan</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compile_model(filename, model_name<span class="op">=</span><span class="va">None</span>, <span class="op">**</span>kwargs):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""This will automatically cache models - great if you're just running a</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">     script on the command line.</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">    See http://pystan.readthedocs.io/en/latest/avoiding_recompilation.html"""</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> hashlib <span class="im">import</span> md5</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> <span class="bu">open</span>(filename) <span class="im">as</span> f:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    model_code <span class="op">=</span> f.read()</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    code_hash <span class="op">=</span> md5(model_code.encode(<span class="st">'ascii'</span>)).hexdigest()</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model_name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>      cache_fn <span class="op">=</span> <span class="st">'cached-model-</span><span class="sc">{}</span><span class="st">.pkl'</span>.<span class="bu">format</span>(code_hash)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>      cache_fn <span class="op">=</span> <span class="st">'cached-</span><span class="sc">{}</span><span class="st">-</span><span class="sc">{}</span><span class="st">.pkl'</span>.<span class="bu">format</span>(model_name, code_hash) </span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>      sm <span class="op">=</span> pickle.load(<span class="bu">open</span>(cache_fn, <span class="st">'rb'</span>))</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>      sm <span class="op">=</span> pystan.StanModel(model_code<span class="op">=</span>model_code)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>      <span class="cf">with</span> <span class="bu">open</span>(cache_fn, <span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        pickle.dump(sm, f)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>       <span class="bu">print</span>(<span class="st">"Using cached StanModel"</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="hamiltonian-monte-carlo-diagnostics" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Hamiltonian Monte Carlo Diagnostics</h1>
<p>Hamiltonian Monte Carlo introduces a suite of powerful diagnostics that can identify obstructions to Markov chain Monte Carlo central limit theorems. These diagnostics are not only extremely sensitive but also probe the behavior of the entire Markov chain state instead of the projections of that state through single expectands.</p>
<section id="check-hamiltonian-monte-carlo-diagnostics" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="check-hamiltonian-monte-carlo-diagnostics"><span class="header-section-number">1.1</span> Check Hamiltonian Monte Carlo Diagnostics</h2>
<p>All of our diagnostics are assembled in this single <code>check_all_hmc_diagnostics</code> function.</p>
<p>The first diagnostic looks for unstable numerical Hamiltonian trajectories, or divergences. These unstable trajectories are known to obstruct typical central limit theorem conditions. Divergences arise when the target distribution is compressed into a narrow region; this forces the Hamiltonian dynamics to accelerate which makes them more difficult to accurately simulate.</p>
<p>Increasing <code>adapt_delta</code> will on average result in a less aggressive step size optimization that in some cases may improve the stability of the numerical integration but at the cost of longer, and hence more expensive, numerical Hamiltonian trajectories. In most cases, however, the only productive way to avoid divergences is to reparameterize the ambient space to decompress these pinches in the target distribution.</p>
<p>Stan’s Hamiltonian Monte Carlo sampler expands the length of the numerical Hamiltonian trajectories dynamically to maximize the efficiency of the exploration. That length, however, is capped at <span class="math inline">2^{\text{max\_treedepth}}</span> steps to prevent trajectories from growing without bound.</p>
<p>When numerical Hamiltonian trajectories are long but finite this truncation will limit the computational efficiency. Increasing <code>max_treedepth</code> allow the trajectories to expand further. While the resulting trajectories will be more expensive that added cost will be more than made up for by increased computational efficiency.</p>
<p>The energy fraction of missing information, or E-FMI, quantifies how well the Hamiltonian dynamics are able to explore the target distribution. If the E-FMI is too small then even the exact Hamiltonian trajectories will be limited to confined regions of the ambient space and full exploration will be possible only with the momenta resampling between trajectories. In this case the Markov chain exploration devolves into less efficient, diffusive behavior where Markov chain Monte Carlo estimation is fragile at best.</p>
<p>This confinement is caused by certain geometries in the target distribution, most commonly a funnel geometry where some subset of parameters shrink together as another parameter ranges across its typical values. The only way to avoid these problems is to identify the problematic geometry and then find a reparameterization of the ambient space that transforms the geometry into something more pleasant.</p>
<p>Finally the average proxy accept statistic is a summary for Stan’s step size adaptation. During warmup the integrator step size is dynamically tuned until this statistic achieves the target value which defaults to <span class="math inline">0.801</span>. Because this adaptation is stochastic the realized average during the main sampling phase can often vary between <span class="math inline">0.75</span> and <span class="math inline">0.85</span>.</p>
<p>So long as the target distribution is sufficiently well-behaved then the adaptation should always converge to that target, at least for long enough warmup periods. Small averages indicate some obstruction to the adaptation, for example discontinuities in the target distribution or inaccurate gradient evaluations.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_all_hmc_diagnostics(fit,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>                              adapt_target<span class="op">=</span><span class="fl">0.801</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>                              max_treedepth<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check all Hamiltonian Monte Carlo Diagnostics for an </span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">     ensemble of Markov chains"""</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check divergences</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  divergent <span class="op">=</span> [x <span class="cf">for</span> y <span class="kw">in</span> sampler_params <span class="cf">for</span> x <span class="kw">in</span> y[<span class="st">'divergent__'</span>]]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> <span class="bu">sum</span>(divergent)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(divergent)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> n <span class="op">&gt;</span> <span class="dv">0</span>: </span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span>n<span class="sc">:.0f}</span><span class="ss"> of </span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> iterations ended with a divergence (</span><span class="sc">{</span>n <span class="op">/</span> N<span class="sc">:.2%}</span><span class="ss">)'</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(   <span class="st">'  Divergences are due unstable numerical integration.</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span>  <span class="st">'  These instabilities are often due to posterior degeneracies.</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span>  <span class="st">'  If there are only a small number of divergences then running</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="ss">f'with adapt_delta larger than </span><span class="sc">{</span>adapt_target<span class="sc">:.3f}</span><span class="ss"> may reduce the</span><span class="ch">\n</span><span class="ss">'</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">'divergences at the cost of more expensive transitions.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check transitions that ended prematurely due to maximum tree depth limit</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  depths <span class="op">=</span> [x <span class="cf">for</span> y <span class="kw">in</span> sampler_params <span class="cf">for</span> x <span class="kw">in</span> y[<span class="st">'treedepth__'</span>]]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>  n <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> x <span class="kw">in</span> depths <span class="cf">if</span> x <span class="op">==</span> max_treedepth)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(depths)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> n <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="ss">f'</span><span class="sc">{</span>n<span class="sc">:.0f}</span><span class="ss"> of </span><span class="sc">{</span>N<span class="sc">}</span><span class="ss"> iterations saturated the maximum tree depth of '</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="ss">f'</span><span class="sc">{</span>max_treedepth<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>n <span class="op">/</span> N<span class="sc">:.2%}</span><span class="ss">)'</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  Increasing max_depth will increase the efficiency of the '</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">'transitions.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Checks the energy fraction of missing information (E-FMI)</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>  no_efmi_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> chain_num, s <span class="kw">in</span> <span class="bu">enumerate</span>(sampler_params):</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    energies <span class="op">=</span> s[<span class="st">'energy__'</span>]</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    numer <span class="op">=</span> <span class="bu">sum</span>((energies[i] <span class="op">-</span> energies[i <span class="op">-</span> <span class="dv">1</span>])<span class="op">**</span><span class="dv">2</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(energies))) <span class="op">/</span> <span class="bu">len</span>(energies)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    denom <span class="op">=</span> numpy.var(energies)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> numer <span class="op">/</span> denom <span class="op">&lt;</span> <span class="fl">0.2</span>:</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>      no_efmi_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>chain_num <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: E-FMI = </span><span class="sc">{</span>numer <span class="op">/</span> denom<span class="sc">:.3f}</span><span class="ss">.'</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_efmi_warning:</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  E-FMI below 0.2 suggests a funnel-like geometry hiding'</span>)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'somewhere in the posterior distribution.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check convergence of the stepsize adaptation</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>  no_accept_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> chain_num, s <span class="kw">in</span> <span class="bu">enumerate</span>(sampler_params):</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>    ave_accept_proxy <span class="op">=</span> numpy.mean(s[<span class="st">'accept_stat__'</span>])</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ave_accept_proxy <span class="op">&lt;</span> <span class="fl">0.9</span> <span class="op">*</span> adapt_target:</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>      no_accept_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(  <span class="ss">f'Chain </span><span class="sc">{</span>chain_num <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Average proxy acceptance statistic '</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> <span class="ss">f'(</span><span class="sc">{</span>ave_accept_proxy<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(  <span class="ss">f'         is smaller than 90% of the target '</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> <span class="ss">f'(</span><span class="sc">{</span>adapt_target<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_accept_warning:</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  A small average proxy acceptance statistic indicates that the'</span>)</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'integrator step size adaptation failed to converge.  This is often'</span>)</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'due to discontinuous or inexact gradients.</span><span class="ch">\n\n</span><span class="st">'</span>)</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'All Hamiltonian Monte Carlo diagnostics are consistent with'</span>)</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'accurate Markov chain Monte Carlo.</span><span class="ch">\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="integrator-inverse-metric-elements" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="integrator-inverse-metric-elements"><span class="header-section-number">1.2</span> Integrator Inverse Metric Elements</h2>
<p>Diagnostic failures indicate the presence of problems but only hint at the nature of those problems. In order to resolve the underlying problems we need to investigate them beyond these hints. Fortunately Hamiltonian Monte Carlo provides a wealth of additional information that can assist.</p>
<p>First we can look at the inverse metric adaptation in each of the Markov chains. Inconsistencies in the adapted inverse metric elements across the Markov chains are due to the individual chains encountering different behaviors during warmup.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_inv_metric(fit, B<span class="op">=</span><span class="dv">25</span>):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Plot outcome of inverse metric adaptation"""</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  chain_info <span class="op">=</span> fit.get_adaptation_info()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> <span class="bu">len</span>(chain_info)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  inv_metric_elems <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> C</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c, raw_info <span class="kw">in</span> <span class="bu">enumerate</span>(chain_info):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    clean1 <span class="op">=</span> re.sub(<span class="st">"# Adaptation terminated</span><span class="ch">\n</span><span class="st"># Step size = [0-9.]*</span><span class="ch">\n</span><span class="st">#"</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>                    <span class="st">""</span>, raw_info)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    clean2 <span class="op">=</span> re.sub(<span class="st">" [a-zA-Z ]*:</span><span class="ch">\n</span><span class="st"># "</span>, <span class="st">""</span>, clean1)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    clean3 <span class="op">=</span> re.sub(<span class="st">"</span><span class="ch">\n</span><span class="st">$"</span>, <span class="st">""</span>, clean2)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    inv_metric_elems[c] <span class="op">=</span> [<span class="bu">float</span>(s) <span class="cf">for</span> s <span class="kw">in</span> clean3.split(<span class="st">','</span>)]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  min_elem <span class="op">=</span> <span class="bu">min</span>([ <span class="bu">min</span>(a) <span class="cf">for</span> a <span class="kw">in</span> inv_metric_elems ])</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  max_elem <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(a) <span class="cf">for</span> a <span class="kw">in</span> inv_metric_elems ])</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  delta <span class="op">=</span> (max_elem <span class="op">-</span> min_elem) <span class="op">/</span> B</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  min_elem <span class="op">=</span> min_elem <span class="op">-</span> delta</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  max_elem <span class="op">=</span> max_elem <span class="op">+</span> delta</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  bins <span class="op">=</span> numpy.arange(min_elem, max_elem <span class="op">+</span> delta, delta)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  B <span class="op">=</span> B <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>  max_y <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(numpy.histogram(a, bins<span class="op">=</span>bins)[<span class="dv">0</span>]) <span class="cf">for</span> a <span class="kw">in</span> inv_metric_elems ])</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>  idxs <span class="op">=</span> [ idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(B) <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>) ]</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>  xs <span class="op">=</span> [ bins[idx <span class="op">+</span> delta] <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(B) <span class="cf">for</span> delta <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">1</span>]]</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>  N_plots <span class="op">=</span> C</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>  N_cols <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>  N_rows <span class="op">=</span> math.ceil(N_plots <span class="op">/</span> N_cols)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>  f, axarr <span class="op">=</span> plot.subplots(N_rows, N_cols)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>  k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>  sci_formatter <span class="op">=</span> matplotlib.ticker.FuncFormatter(<span class="kw">lambda</span> x, lim: <span class="ss">f'</span><span class="sc">{</span>x<span class="sc">:.1e}</span><span class="ss">'</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> numpy.histogram(inv_metric_elems[c], bins<span class="op">=</span>bins)[<span class="dv">0</span>]</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    ys <span class="op">=</span> counts[idxs]</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    eps <span class="op">=</span> sampler_params[c][<span class="st">'stepsize__'</span>][<span class="dv">0</span>]</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    idx1 <span class="op">=</span> k <span class="op">//</span> N_cols</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    idx2 <span class="op">=</span> k <span class="op">%</span> N_cols</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    k <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].plot(xs, ys, dark)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_title(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">(Stepsize = </span><span class="sc">{</span>eps<span class="sc">:.3e}</span><span class="ss">)'</span>)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlabel(<span class="st">"Inverse Metric Elements"</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlim([min_elem, max_elem])</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].get_xaxis().set_major_formatter(sci_formatter)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylabel(<span class="st">""</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].get_yaxis().set_visible(<span class="va">False</span>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylim([<span class="dv">0</span>, <span class="fl">1.05</span> <span class="op">*</span> max_y])</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"left"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>  plot.subplots_adjust(hspace<span class="op">=</span><span class="fl">1.0</span>, wspace<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>  plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="integrator-step-sizes" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="integrator-step-sizes"><span class="header-section-number">1.3</span> Integrator Step Sizes</h2>
<p>The other product of Stan’s adaptation is the step size of the numerical integrator used to build the numerical Hamiltonian trajectories. As with the inverse metric elements heterogeneity in the adapted values across the Markov chains indicates that the Markov chains encountered substantially different behavior during warmup.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_stepsizes(fit):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Display outcome of symplectic integrator step size adaptation"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> chain_num, s <span class="kw">in</span> <span class="bu">enumerate</span>(sampler_params):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    stepsize <span class="op">=</span> s[<span class="st">'stepsize__'</span>][<span class="dv">0</span>]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>chain_num <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Integrator Step Size = </span><span class="sc">{</span>stepsize<span class="sc">:.2e}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="numerical-trajectory-lengths" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="numerical-trajectory-lengths"><span class="header-section-number">1.4</span> Numerical Trajectory Lengths</h2>
<p>We can see the consequence of the adapted step sizes by looking at the numerical trajectories generated for each Hamiltonian Markov transition. The longer these trajectories the more degenerate the target distribution, and the more expensive it is to explore.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_num_leapfrog(fit):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Display symplectic integrator trajectory lenghts"""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  vals_counts <span class="op">=</span> [ numpy.unique(s[<span class="st">'n_leapfrog__'</span>], return_counts<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>                  <span class="cf">for</span> s <span class="kw">in</span> sampler_params ] </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  max_n <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(a[<span class="dv">0</span>]) <span class="cf">for</span> a <span class="kw">in</span> vals_counts ]).astype(numpy.int64)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  max_counts <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(a[<span class="dv">1</span>]) <span class="cf">for</span> a <span class="kw">in</span> vals_counts ])</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  idxs <span class="op">=</span> [ idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(max_n) <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>) ]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  xs <span class="op">=</span> [ idx <span class="op">+</span> delta <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(max_n) <span class="cf">for</span> delta <span class="kw">in</span> [<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>]]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> <span class="bu">len</span>(vals_counts)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  N_plots <span class="op">=</span> C</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  N_cols <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>  N_rows <span class="op">=</span> math.ceil(N_plots <span class="op">/</span> N_cols)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>  f, axarr <span class="op">=</span> plot.subplots(N_rows, N_cols)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c, s <span class="kw">in</span> <span class="bu">enumerate</span>(sampler_params):</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    counts <span class="op">=</span> numpy.histogram(s[<span class="st">'n_leapfrog__'</span>], </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                             bins<span class="op">=</span>numpy.arange(<span class="fl">0.5</span>, max_n <span class="op">+</span> <span class="fl">1.5</span>, <span class="dv">1</span>))[<span class="dv">0</span>]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    ys <span class="op">=</span> counts[idxs]</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    eps <span class="op">=</span> s[<span class="st">'stepsize__'</span>][<span class="dv">0</span>]</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    idx1 <span class="op">=</span> k <span class="op">//</span> N_cols</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    idx2 <span class="op">=</span> k <span class="op">%</span> N_cols</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    k <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].plot(xs, ys, dark)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_title(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">(Stepsize = </span><span class="sc">{</span>eps<span class="sc">:.3e}</span><span class="ss">)'</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlabel(<span class="st">"Numerical Trajectory Length"</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlim([<span class="fl">0.5</span>, max_n <span class="op">+</span> <span class="fl">0.5</span>])</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylabel(<span class="st">""</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].get_yaxis().set_visible(<span class="va">False</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylim([<span class="dv">0</span>, <span class="fl">1.1</span> <span class="op">*</span> max_counts])</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>  plot.subplots_adjust(hspace<span class="op">=</span><span class="fl">1.0</span>, wspace<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>  plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="average-proxy-acceptance-statistic" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="average-proxy-acceptance-statistic"><span class="header-section-number">1.5</span> Average Proxy Acceptance Statistic</h2>
<p>When the different adaptation outcomes are due to problematic behaviors encountered during warmup then it the average proxy acceptance statistics should also vary across the Markov chains.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_ave_accept_proxy(fit):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Display empirical average of the proxy acceptance statistic</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">     across each individual Markov chains"""</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c, s <span class="kw">in</span> <span class="bu">enumerate</span>(sampler_params):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    ave_accept_proxy <span class="op">=</span> numpy.mean(s[<span class="st">'accept_stat__'</span>])</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: '</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="ss">f'Average proxy acceptance statistic = </span><span class="sc">{</span>ave_accept_proxy<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="divergence-labeled-pairs-plot" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="divergence-labeled-pairs-plot"><span class="header-section-number">1.6</span> Divergence-Labeled Pairs Plot</h2>
<p>One of the most powerful features of divergent transitions is that they not only indicate problematic geometry but also provide some spatial information on the source of that problematic geometry. In particular the states generated from unstable numerical Hamiltonian trajectories will tend to be closer to the problematic geometry than those from stable trajectories.</p>
<p>Consequently if we plot the states from divergent and non-divergent transitions separately then we should see the divergent states concentrate towards the problematic behavior. The high-dimensional states themselves can be visualized with pairs plots.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _by_chain(unpermuted_extraction):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  num_chains <span class="op">=</span> <span class="bu">len</span>(unpermuted_extraction[<span class="dv">0</span>])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  result <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_chains)]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(num_chains):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(unpermuted_extraction)):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>      result[c].append(unpermuted_extraction[i][c])</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> numpy.array(result)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _shaped_ordered_params(fit):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># flattened, unpermuted, by (iteration, chain)</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  ef <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>, inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  ef <span class="op">=</span> _by_chain(ef)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  ef <span class="op">=</span> ef.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="bu">len</span>(ef[<span class="dv">0</span>][<span class="dv">0</span>]))</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  ef <span class="op">=</span> ef[:, <span class="dv">0</span>:<span class="bu">len</span>(fit.flatnames)] <span class="co"># drop lp__</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  shaped <span class="op">=</span> {}</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> dim, param_name <span class="kw">in</span> <span class="bu">zip</span>(fit.par_dims, fit.extract().keys()):</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    length <span class="op">=</span> <span class="bu">int</span>(numpy.prod(dim))</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    shaped[param_name] <span class="op">=</span> ef[:,idx:idx <span class="op">+</span> length]</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    shaped[param_name].reshape(<span class="op">*</span>([<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> dim))</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">+=</span> length</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> shaped</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> partition_div(fit):</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Separate Markov chain states into those sampled from non-divergent</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="co">     numerical Hamiltonian trajectories and those sampled from divergent</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co">     numerical Hamiltonian trajectories"""</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>  sampler_params <span class="op">=</span> fit.get_sampler_params(inc_warmup<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  div <span class="op">=</span> numpy.concatenate([x[<span class="st">'divergent__'</span>] <span class="cf">for</span> x <span class="kw">in</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>                           sampler_params]).astype(<span class="st">'int'</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>  params <span class="op">=</span> _shaped_ordered_params(fit)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>  nondiv_params <span class="op">=</span> <span class="bu">dict</span>((key, params[key][div <span class="op">==</span> <span class="dv">0</span>]) <span class="cf">for</span> key <span class="kw">in</span> params)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>  div_params <span class="op">=</span> <span class="bu">dict</span>((key, params[key][div <span class="op">==</span> <span class="dv">1</span>]) <span class="cf">for</span> key <span class="kw">in</span> params)</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> nondiv_params, div_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_div_pairs(fit, names, transforms):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Plot pairwise scatter plots with non-divergent and divergent </span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">     transitions separated by color"""</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  nondiv_samples, div_samples <span class="op">=</span> partition_div(fit)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  N_nondiv <span class="op">=</span> <span class="bu">len</span>(nondiv_samples[<span class="bu">list</span>(nondiv_samples.keys())[<span class="dv">0</span>]])</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  N_div <span class="op">=</span> <span class="bu">len</span>(div_samples[<span class="bu">list</span>(div_samples.keys())[<span class="dv">0</span>]])</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(names)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  N_plots <span class="op">=</span> math.comb(N, <span class="dv">2</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  N_cols <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  N_rows <span class="op">=</span> math.ceil(N_plots <span class="op">/</span> N_cols)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  f, axarr <span class="op">=</span> plot.subplots(N_rows, N_cols)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(N <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> m <span class="kw">in</span> <span class="bu">range</span>(n <span class="op">+</span> <span class="dv">1</span>, N):</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>      name_x <span class="op">=</span> names[n]</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> re.search(<span class="st">'\['</span>, name_x):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        base_name, idxs <span class="op">=</span> name_x.split(<span class="st">'['</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        index_name_x <span class="op">=</span> base_name</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        idxs <span class="op">=</span> re.sub(<span class="st">'\]'</span>, <span class="st">''</span>, idxs)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        nondiv_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_nondiv)]) <span class="op">+</span> <span class="bu">tuple</span>([<span class="bu">int</span>(s) <span class="op">-</span> <span class="dv">1</span> <span class="cf">for</span> s <span class="kw">in</span> idxs.split(<span class="st">','</span>)])</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        div_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_div)]) <span class="op">+</span> <span class="bu">tuple</span>([<span class="bu">int</span>(s) <span class="op">-</span> <span class="dv">1</span> <span class="cf">for</span> s <span class="kw">in</span> idxs.split(<span class="st">','</span>)])</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        index_name_x <span class="op">=</span> name_x</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        nondiv_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_nondiv)]) <span class="op">+</span> (<span class="dv">0</span>,)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        div_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_div)]) <span class="op">+</span> (<span class="dv">0</span>,)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> transforms[n] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        x_nondiv_samples <span class="op">=</span> nondiv_samples[index_name_x][nondiv_idxs]</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        x_div_samples <span class="op">=</span> div_samples[index_name_x][div_idxs]</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        x_name <span class="op">=</span> name_x</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> transforms[n] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        x_nondiv_samples <span class="op">=</span> [math.log(x) <span class="cf">for</span> x <span class="kw">in</span> nondiv_samples[index_name_x][nondiv_idxs]]</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>        x_div_samples <span class="op">=</span> [math.log(x) <span class="cf">for</span> x <span class="kw">in</span> div_samples[index_name_x][div_idxs]]</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        x_name <span class="op">=</span> <span class="st">"log("</span> <span class="op">+</span> name_x <span class="op">+</span> <span class="st">")"</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>      xmin <span class="op">=</span> <span class="bu">min</span>(numpy.concatenate((x_nondiv_samples, x_div_samples)))</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>      xmax <span class="op">=</span> <span class="bu">max</span>(numpy.concatenate((x_nondiv_samples, x_div_samples)))</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>      name_y <span class="op">=</span> names[m]</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> re.search(<span class="st">'\['</span>, name_y):</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        base_name, idxs <span class="op">=</span> name_y.split(<span class="st">'['</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        index_name_y <span class="op">=</span> base_name</span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        idxs <span class="op">=</span> re.sub(<span class="st">'\]'</span>, <span class="st">''</span>, idxs)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>        nondiv_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_nondiv)]) <span class="op">+</span> <span class="bu">tuple</span>([<span class="bu">int</span>(s) <span class="op">-</span> <span class="dv">1</span> <span class="cf">for</span> s <span class="kw">in</span> idxs.split(<span class="st">','</span>)])</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>        div_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_div)]) <span class="op">+</span> <span class="bu">tuple</span>([<span class="bu">int</span>(s) <span class="op">-</span> <span class="dv">1</span> <span class="cf">for</span> s <span class="kw">in</span> idxs.split(<span class="st">','</span>)])</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span>:</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>        index_name_y <span class="op">=</span> name_y</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>        nondiv_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_nondiv)]) <span class="op">+</span> (<span class="dv">0</span>,)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>        div_idxs <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">slice</span>(<span class="dv">0</span>, N_div)]) <span class="op">+</span> (<span class="dv">0</span>,)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> transforms[m] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>        y_nondiv_samples <span class="op">=</span> nondiv_samples[index_name_y][nondiv_idxs]</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>        y_div_samples <span class="op">=</span> div_samples[index_name_y][div_idxs]</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>        y_name <span class="op">=</span> name_y</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> transforms[m] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>        y_nondiv_samples <span class="op">=</span> [math.log(y) <span class="cf">for</span> y <span class="kw">in</span> nondiv_samples[index_name_y][nondiv_idxs]]</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>        y_div_samples <span class="op">=</span> [math.log(y) <span class="cf">for</span> y <span class="kw">in</span> div_samples[index_name_y][div_idxs]]</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>        y_name <span class="op">=</span> <span class="st">"log("</span> <span class="op">+</span> name_y <span class="op">+</span> <span class="st">")"</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>      ymin <span class="op">=</span> <span class="bu">min</span>(numpy.concatenate((y_nondiv_samples, y_div_samples)))</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>      ymax <span class="op">=</span> <span class="bu">max</span>(numpy.concatenate((y_nondiv_samples, y_div_samples)))</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>      idx1 <span class="op">=</span> k <span class="op">//</span> N_cols</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>      idx2 <span class="op">=</span> k <span class="op">%</span> N_cols</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>      k <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].scatter(x_nondiv_samples, y_nondiv_samples, s<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>                                color <span class="op">=</span> dark_highlight, alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].scatter(x_div_samples, y_div_samples, s<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>                                color <span class="op">=</span> <span class="st">"#00FF00"</span>, alpha<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].set_xlabel(x_name)</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].set_xlim([xmin, xmax])</span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].set_ylabel(y_name)</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].set_ylim([ymin, ymax])</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>      axarr[idx1, idx2].spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_rows <span class="op">*</span> N_cols <span class="op">-</span> N_plots):</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>    idx1 <span class="op">=</span> k <span class="op">//</span> N_cols</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>    idx2 <span class="op">=</span> k <span class="op">%</span> N_cols</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    k <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].axis(<span class="st">'off'</span>)</span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>  plot.subplots_adjust(hspace<span class="op">=</span><span class="fl">0.75</span>, wspace<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>  plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="expectand-diagnostic-functions" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Expectand Diagnostic Functions</h1>
<p>The Hamiltonian Monte Carlo diagnostics exploited the particular structure of the Hamiltonian Markov transition. For a general Markov transition we don’t have any particular structure to exploit, and hence limited diagnostic options. In this general setting we have to investigate the behavior of not the entire state but instead particular expectands of interest.</p>
<section id="khat" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="khat"><span class="header-section-number">2.1</span> khat</h2>
<p>A Markov chain Monte Carlo central limit theorem cannot exist for the expectand <span class="math inline">f : X \rightarrow \mathbb{R}</span> unless both <span class="math inline">\mathbb{E}_{\pi}[f]</span> and <span class="math inline">\mathbb{E}_{\pi}[f^{2}]</span> are finite, in which case we say that the expectand is sufficiently integrable. Moreover the smaller the following moments the faster the central limit theorem kicks in.</p>
<p><span class="math inline">\hat{k}</span> uses the tail behavior of a realized Markov chain to estimate the integrability of an expectand. More specifically <span class="math inline">\hat{k}</span> estimates the shape of a Pareto density function from non-central values of the expectand. If the tail behavior were exactly Pareto with shape parameter <span class="math inline">k</span> then only the <span class="math inline">(1 / k)</span>-th order and lower moments would exist. For example with <span class="math inline">k = 1</span> the expectation <span class="math inline">\mathbb{E}_{\pi}[f]</span> is finite but <span class="math inline">\mathbb{E}_{\pi}[f^{2}]</span> is not, while for <span class="math inline">k = \frac{1}{2}</span> the expectations <span class="math inline">\mathbb{E}_{\pi}[f]</span> and <span class="math inline">\mathbb{E}_{\pi}[f^{2}]</span> are finite but <span class="math inline">\mathbb{E}_{\pi}[f^{3}]</span> is not.</p>
<p>The estimator <span class="math inline">\hat{k}</span> is constructed from the smallest and largest values of an expectand evaluated across a realized Markov chain, where the smallest and largest values are separated from the central values using a heuristic. Because <span class="math inline">\hat{k}</span> only estimates the tail shape I require a conservative threshold of <span class="math inline">\hat{k} \ge 0.25</span> for the diagnostic warning to be triggered.</p>
<p>If the expectand output is bounded then the lower and upper tail might consist of the same value. In this case the <span class="math inline">\hat{k}</span> estimator is poorly-behaved, but the boundedness also guarantees that moments of all orders exist. To make this diagnostic as robust as possible <span class="math inline">\hat{k}</span> will return <span class="math inline">-2</span> in these cases to avoid the diagnostic threshold.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_khat(fs):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute empirical Pareto shape for a positive sample"""</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(fs)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  sorted_fs <span class="op">=</span> <span class="bu">sorted</span>(fs)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> sorted_fs[<span class="dv">0</span>] <span class="op">==</span> sorted_fs[<span class="op">-</span><span class="dv">1</span>]:</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (sorted_fs[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="dv">0</span>):</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Sequence values must be positive!"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> NaN</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Estimate 25% quantile</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  q <span class="op">=</span> sorted_fs[math.floor(<span class="fl">0.25</span> <span class="op">*</span> N <span class="op">+</span> <span class="fl">0.5</span>)]</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> q <span class="op">==</span> sorted_fs[<span class="dv">0</span>]:</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Heurstic Pareto configuration</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  M <span class="op">=</span> <span class="dv">20</span> <span class="op">+</span> math.floor(math.sqrt(N))</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  b_hat_vec <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> M</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  log_w_vec <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> M</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> m <span class="kw">in</span> <span class="bu">range</span>(M):</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    b_hat_vec[m] <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> sorted_fs[<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> math.sqrt(M <span class="op">/</span> (m <span class="op">+</span> <span class="fl">0.5</span>))) <span class="op">/</span> (<span class="dv">3</span> <span class="op">*</span> q)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> b_hat_vec[m] <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>      k_hat <span class="op">=</span> <span class="op">-</span> numpy.mean( [ math.log(<span class="dv">1</span> <span class="op">-</span> b_hat_vec[m] <span class="op">*</span> f) <span class="cf">for</span> f <span class="kw">in</span> sorted_fs ] )</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>      log_w_vec[m] <span class="op">=</span> N <span class="op">*</span> ( math.log(b_hat_vec[m] <span class="op">/</span> k_hat) <span class="op">+</span> k_hat <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>      log_w_vec[m] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Remove terms that don't contribute to improve numerical stability of average</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>  log_w_vec <span class="op">=</span> [ lw <span class="cf">for</span> lw <span class="kw">in</span> log_w_vec <span class="cf">if</span> lw <span class="op">!=</span> <span class="dv">0</span> ]</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>  b_hat_vec <span class="op">=</span> [ b <span class="cf">for</span> b <span class="kw">in</span> b_hat_vec <span class="cf">if</span> b <span class="op">!=</span> <span class="dv">0</span> ]</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  max_log_w <span class="op">=</span> <span class="bu">max</span>(log_w_vec)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>  b_hat <span class="op">=</span> <span class="bu">sum</span>( [ b <span class="op">*</span> math.exp(lw <span class="op">-</span> max_log_w) <span class="cf">for</span> b, lw <span class="kw">in</span> <span class="bu">zip</span>(b_hat_vec, log_w_vec) ] ) <span class="op">/\</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>          <span class="bu">sum</span>( [ math.exp(lw <span class="op">-</span> max_log_w) <span class="cf">for</span> lw <span class="kw">in</span> log_w_vec ] )</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> numpy.mean( [ math.log(<span class="dv">1</span> <span class="op">-</span> b_hat <span class="op">*</span> f) <span class="cf">for</span> f <span class="kw">in</span> sorted_fs ] )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_tail_khats(fs):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute empirical Pareto shape for upper and lower tails"""</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  f_center <span class="op">=</span> numpy.median(fs)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  fs_left <span class="op">=</span> [ math.fabs(f <span class="op">-</span> f_center) <span class="cf">for</span> f <span class="kw">in</span> fs <span class="cf">if</span> f <span class="op">&lt;=</span> f_center ]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  fs_right <span class="op">=</span> [ f <span class="op">-</span> f_center <span class="cf">for</span> f <span class="kw">in</span> fs <span class="cf">if</span> f <span class="op">&gt;</span> f_center ]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Default to -2 if left tail is ill-defined</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  khat_left <span class="op">=</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(fs_left) <span class="op">&gt;</span> <span class="dv">40</span>:</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    khat_left <span class="op">=</span> compute_khat(fs_left)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Default to -2 if right tail is ill-defined</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  khat_right <span class="op">=</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(fs_right) <span class="op">&gt;</span> <span class="dv">40</span>:</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    khat_right <span class="op">=</span> compute_khat(fs_right)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [khat_left, khat_right]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_tail_khats(unpermuted_samples):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check empirical Pareto shape for upper and lower tails of a</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">     given expectand output ensemble"""</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> <span class="bu">len</span>(unpermuted_samples[<span class="dv">0</span>,:])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    fs <span class="op">=</span> unpermuted_samples[:,c]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    khats <span class="op">=</span> compute_tail_khats(fs)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> khats[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span>:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Both left and right tail khats exceed 0.25!'</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> khats[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span>:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Right tail khat exceeds 0.25!'</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> khats[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&lt;</span> <span class="fl">0.25</span>:</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Left tail khat exceeds 0.25!'</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Expectand appears to be sufficiently integrable.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  Large tail khats suggest that the expectand might'</span>)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'not be sufficiently integrable.</span><span class="ch">\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="frozen-chains" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="frozen-chains"><span class="header-section-number">2.2</span> Frozen Chains</h2>
<p>Another sign of problems is when all evaluations of an expectand are constant. This could be due to the Markov chain being stuck at a single state or just that the pushforward distribution of the expectand concentrates on a single value. We can’t distinguish between these possibilities without more information, but we can signal a constant expectand by looking at its empirical variance.</p>
<p>Here we’ll use a Welford accumulator to compute the empirical variance of the expectand values in a single sweep.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> welford_summary(fs):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Welford accumulator for empirical mean and variance of a given sequence"""</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  mean <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  var <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> n, f <span class="kw">in</span> <span class="bu">enumerate</span>(fs):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    delta <span class="op">=</span> f <span class="op">-</span> mean</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">+=</span> delta <span class="op">/</span> (n <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    var <span class="op">+=</span> delta <span class="op">*</span> (f <span class="op">-</span> mean)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  var <span class="op">/=</span> (<span class="bu">len</span>(fs) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [mean, var]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_variances(unpermuted_samples):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check expectand output ensemble for vanishing empirical variance"""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> <span class="bu">len</span>(unpermuted_samples[<span class="dv">0</span>,:])</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    fs <span class="op">=</span> unpermuted_samples[:,c]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    var <span class="op">=</span> welford_summary(fs)[<span class="dv">1</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> var <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Expectand is constant!</span><span class="ch">\n</span><span class="ss">'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Expectand is varying in all Markov chains.'</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  If the expectand is not expected (haha) to be'</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'constant then the Markov transitions are misbehaving.</span><span class="ch">\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="split-rhat" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="split-rhat"><span class="header-section-number">2.3</span> Split Rhat</h2>
<p>One of the key features of Markov chain equilibrium is that the distribution of Markov chain realizations is independent of the initialization. In particular the expectand evaluations from any equilibrated Markov chain should be statistically equivalent to any other. Even more the evaluations across any subset of Markov chain states should be equivalent.</p>
<p>The split <span class="math inline">\hat{R}</span> statistic quantifies the heterogeneity in the expectand evaluations across an ensemble of Markov chains, each of which has been split in half. Mathematically split <span class="math inline">\hat{R}</span> is similar to analysis of variance in that compares the empirical variance of the average expectand values in each chain half to the average of the empirical variances in each chain half; the key difference is that split <span class="math inline">\hat{R}</span> transforms this ratio so that in equilibrium the statistic decays towards <span class="math inline">1</span> from above.</p>
<p>When split <span class="math inline">\hat{R}</span> is much larger than <span class="math inline">1</span> the expectand evaluations across each Markov chain halves are not consistent with each other. This could be because the Markov chains have not converged to the same typical set or because they have not yet expanded into that typical set.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> split_chain(chain):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Split a Markov chain into initial and terminal Markov chains"""</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(chain)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  M <span class="op">=</span> N <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [ chain[<span class="dv">0</span>:M], chain[M:N] ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_split_rhat(chains):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute split hat{R} for an expectand output ensemble across</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">     a collection of Markov chains"""</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  split_chains <span class="op">=</span> [ c <span class="cf">for</span> chain <span class="kw">in</span> chains <span class="cf">for</span> c <span class="kw">in</span> split_chain(chain) ]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  N_chains <span class="op">=</span> <span class="bu">len</span>(split_chains)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">sum</span>([ <span class="bu">len</span>(chain) <span class="cf">for</span> chain <span class="kw">in</span> split_chains ])</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>  means <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> N_chains</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span class="bu">vars</span> <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> N_chains</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c, chain <span class="kw">in</span> <span class="bu">enumerate</span>(split_chains):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> welford_summary(chain)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    means[c] <span class="op">=</span> summary[<span class="dv">0</span>]</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">vars</span>[c] <span class="op">=</span> summary[<span class="dv">1</span>]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  total_mean <span class="op">=</span> <span class="bu">sum</span>(means) <span class="op">/</span> N_chains</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  W <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">vars</span>) <span class="op">/</span> N_chains</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>  B <span class="op">=</span> N <span class="op">*</span> <span class="bu">sum</span>([ (mean <span class="op">-</span> total_mean)<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> (N_chains <span class="op">-</span> <span class="dv">1</span>) <span class="cf">for</span> mean <span class="kw">in</span> means ])</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  rhat <span class="op">=</span> math.nan</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">abs</span>(W) <span class="op">&gt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    rhat <span class="op">=</span> math.sqrt( (N <span class="op">-</span> <span class="dv">1</span> <span class="op">+</span> B <span class="op">/</span> W) <span class="op">/</span> N )</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> rhat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_split_rhats(fit, expectand_idxs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute split hat{R} for all expectand output ensembles across</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">     a collection of Markov chains"""</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  unpermuted_samples <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  I <span class="op">=</span> input_dims[<span class="dv">2</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> expectand_idxs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">range</span>(I)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  bad_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(<span class="bu">range</span>(I))</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(bad_idxs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Excluding the invalid expectand indices: </span><span class="sc">{</span>bad_idxs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(bad_idxs)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  rhats <span class="op">=</span> []</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idx <span class="kw">in</span> expectand_idxs:</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    chains <span class="op">=</span> [ unpermuted_samples[:,c,idx] <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    rhats.append(compute_split_rhat(chains))</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> rhats</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_rhat(unpermuted_samples):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check split hat{R} for all expectand output ensembles across</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">     a collection of Markov chains"""</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> unpermuted_samples.shape[<span class="dv">1</span>]</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  chains <span class="op">=</span> [ unpermuted_samples[:,c] <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ]</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  rhat <span class="op">=</span> compute_split_rhat(chains)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> math.isnan(rhat):</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'All Markov chains are frozen!'</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> rhat <span class="op">&gt;</span> <span class="fl">1.1</span>:</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Split rhat is </span><span class="sc">{</span>rhat<span class="sc">:.3f}</span><span class="ss">!'</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Markov chains are consistent with equilibrium.'</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  Split rhat larger than 1.1 is inconsistent with equilibrium.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="integrated-autocorrelation-time" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="integrated-autocorrelation-time"><span class="header-section-number">2.4</span> Integrated Autocorrelation Time</h2>
<p>The information about the target distribution encoded within a Markov chain, and hence the potential precision of Markov chain Monte Carlo estimators, is limited by the autocorrelation of the internal states. Assuming equilibrium we can estimate the stationary autocorrelations between the outputs of a given expectand from the realized Markov chain and then combine them into an estimate of the integrated autocorrelation time which moderates the asymptotic variance of well-behaved Markov chain Monte Carlo estimators.</p>
<p>If this empirical integrated autocorrelation time is a substantial proportion of the length of the realized Markov chain then there won’t be enough information to supply robust Markov chain Monte Carlo estimators. Here I set the diagnostic warning to a quarter of the total number of iterations.</p>
<p>When Markov chains have not equilibrated the empirical autocorrelation time will not longer be related to the error of Markov chain Monte Carlo estimators. That said it still provides a useful quantification of the autocorrelations within a realized Markov chain. In particular it provides a useful way to distinguish if some diagnostic failures are due to Markov chains that are just too short or more persistent problems.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_tauhat(fs):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute empirical integrated autocorrelation time for a sequence"""</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute empirical autocorrelations</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(fs)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  m, v <span class="op">=</span> welford_summary(fs)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  zs <span class="op">=</span> [ f <span class="op">-</span> m <span class="cf">for</span> f <span class="kw">in</span> fs ]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> v <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Inf</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>  B <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>math.ceil(math.log2(N)) <span class="co"># Next power of 2 after N</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  zs_buff <span class="op">=</span> zs <span class="op">+</span> [<span class="dv">0</span>] <span class="op">*</span> (B <span class="op">-</span> N)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>  Fs <span class="op">=</span> numpy.fft.fft(zs_buff)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  Ss <span class="op">=</span> numpy.<span class="bu">abs</span>(Fs)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  Rs <span class="op">=</span> numpy.fft.ifft(Ss)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>  acov_buff <span class="op">=</span> numpy.real(Rs)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>  rhos <span class="op">=</span> acov_buff[<span class="dv">0</span>:N] <span class="op">/</span> acov_buff[<span class="dv">0</span>]</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Drop last lag if (L + 1) is odd so that the lag pairs are complete</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>  L <span class="op">=</span> N</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (L <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> L <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Number of lag pairs</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>  P <span class="op">=</span> (L <span class="op">+</span> <span class="dv">1</span>) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Construct asymptotic correlation from initial monotone sequence</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>  old_pair_sum <span class="op">=</span> rhos[<span class="dv">0</span>] <span class="op">+</span> rhos[<span class="dv">1</span>]</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> p <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, P):</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    current_pair_sum <span class="op">=</span> rhos[<span class="dv">2</span> <span class="op">*</span> p] <span class="op">+</span> rhos[<span class="dv">2</span> <span class="op">*</span> p <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_pair_sum <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>      rho_sum <span class="op">=</span> <span class="bu">sum</span>(rhos[<span class="dv">1</span>:(<span class="dv">2</span> <span class="op">*</span> p)])</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> rho_sum <span class="op">&lt;=</span> <span class="op">-</span><span class="fl">0.25</span>:</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        rho_sum <span class="op">=</span> <span class="op">-</span><span class="fl">0.25</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>      asymp_corr <span class="op">=</span> <span class="fl">1.0</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> rho_sum</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> asymp_corr</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_pair_sum <span class="op">&gt;</span> old_pair_sum:</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>      current_pair_sum <span class="op">=</span> old_pair_sum</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>      rhos[<span class="dv">2</span> <span class="op">*</span> p]     <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> old_pair_sum</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>      rhos[<span class="dv">2</span> <span class="op">*</span> p <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> old_pair_sum</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if p == P:</span></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>      <span class="co"># throw some kind of error when autocorrelation</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>      <span class="co"># sequence doesn't get terminated</span></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>    old_pair_sum <span class="op">=</span> current_pair_sum</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_min_tauhat(fit, expectand_idxs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute the minimimum empirical integrated autocorrelation time</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">     across a collection of Markov chains for all expectand output ensembles"""</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  unpermuted_samples <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  I <span class="op">=</span> input_dims[<span class="dv">2</span>]</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> expectand_idxs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">range</span>(I)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  bad_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(<span class="bu">range</span>(I))</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(bad_idxs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Excluding the invalid expectand indices: </span><span class="sc">{</span>bad_idxs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(bad_idxs)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>  min_int_ac_times <span class="op">=</span> []</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idx <span class="kw">in</span> expectand_idxs:</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    int_ac_times <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> C</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>      fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>      int_ac_times[c] <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    min_int_ac_times.append(<span class="bu">min</span>(int_ac_times))</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> min_int_ac_times</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_min_tauhat(unpermuted_samples):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check the empirical integrated autocorrelation times across a </span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">     collection of Markov chains for all expectand output ensembles"""</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    fs <span class="op">=</span> unpermuted_samples[:,c]</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    int_ac_time <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (int_ac_time <span class="op">/</span> N) <span class="op">&gt;</span> <span class="fl">0.25</span>:</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(  <span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: The integrated autocorrelation time'</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> <span class="st">'exceeds 0.25 * N!'</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Autocorrelations within each Markov chain appear to be reasonable.'</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  Autocorrelations in at least one Markov chain are large enough'</span>)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'that Markov chain Monte Carlo estimates may not be reliable.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Assuming stationarity we can use the empirical integrated autocorrelation time to estimate the effective sample size, and hence the Markov chain Monte Carlo standard error, for any well-behaved expectand estimator <span class="math display">
\hat{f} \approx \mathbb{E}_{\pi}[f].
</span> The desired effective sample size depends on the precision required for a given Markov chain Monte Carlo estimator. This can vary not only from analysis to analysis but also between multiple expectands within a single analysis. That said an effective sample size of <span class="math inline">100</span> is sufficient for most applications and provides a useful rule of thumb.</p>
<p>As with the empirical integrated autocorrelation times we have to be careful with the empirical effective sample sizes. We can construct these estimators from any Markov chain, but if that chain hasn’t reach equilibrium then these estimators will have no connection to Markov chain Monte Carlo error quantification!</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_neff(unpermuted_samples, min_neff_per_chain<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check the empirical effective sample size for all expectand output ensembles"""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  no_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    fs <span class="op">=</span> unpermuted_samples[:,c]</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    int_ac_time <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    neff <span class="op">=</span> N <span class="op">/</span> int_ac_time</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> neff <span class="op">&lt;</span> min_neff_per_chain:</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>      <span class="bu">print</span>(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: The effective sample size </span><span class="sc">{</span>neff<span class="sc">:.1f}</span><span class="ss"> is too small!'</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>      no_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_warning:</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'All effective sample sizes are sufficiently large.'</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'  If the effective sample size is too small then'</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Markov chain Monte Carlo estimators will be imprecise.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="all-expectand-diagnostics" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="all-expectand-diagnostics"><span class="header-section-number">2.5</span> All Expectand Diagnostics</h2>
<p>In practice we have no reason not to check all of these diagnostics at once for each expectand of interest.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_all_expectand_diagnostics(fit,</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>                                    expectand_idxs<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                                    min_neff_per_chain<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                                    exclude_zvar<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Check all expectand diagnostics"""</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  unpermuted_samples <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  I <span class="op">=</span> input_dims[<span class="dv">2</span>]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>  expectand_names <span class="op">=</span> fit.flatnames <span class="op">+</span> [<span class="st">"lp__"</span>]</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> expectand_idxs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">range</span>(I)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  bad_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(<span class="bu">range</span>(I))</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(bad_idxs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Excluding the invalid expectand indices: </span><span class="sc">{</span>bad_idxs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(bad_idxs)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>  no_khat_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>  no_zvar_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>  no_rhat_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>  no_tauhat_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>  no_neff_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>  message <span class="op">=</span> <span class="st">""</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idx <span class="kw">in</span> expectand_idxs:</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>    local_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>    local_message <span class="op">=</span> expectand_names[idx] <span class="op">+</span> <span class="st">':</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> exclude_zvar:</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check zero variance across all Markov chains for exclusion</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>      any_zvar <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>        fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>        var <span class="op">=</span> welford_summary(fs)[<span class="dv">1</span>]</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> var <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>          any_zvar <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> any_zvar:</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>      fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check tail khats in each Markov chain</span></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>      khats <span class="op">=</span> compute_tail_khats(fs)</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> khats[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span>:</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>        no_khat_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span>  <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Both left and right tail hat</span><span class="ch">{{</span><span class="ss">k</span><span class="ch">}}</span><span class="ss">s'</span> \</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="ss">f'(</span><span class="sc">{</span>khats[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>khats[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">) exceed 0.25!</span><span class="ch">\n</span><span class="ss">'</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> khats[<span class="dv">0</span>] <span class="op">&lt;</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span>:</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a>        no_khat_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span>  <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Right tail hat</span><span class="ch">{{</span><span class="ss">k</span><span class="ch">}}</span><span class="ss"> (</span><span class="sc">{</span>khats[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">)'</span> \</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="st">' exceeds 0.25!</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> khats[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span> <span class="kw">and</span> khats[<span class="dv">1</span>] <span class="op">&lt;</span> <span class="fl">0.25</span>:</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>        no_khat_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span>  <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Left tail hat</span><span class="ch">{{</span><span class="ss">k</span><span class="ch">}}</span><span class="ss"> (</span><span class="sc">{</span>khats[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">)'</span> \</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="st">' exceeds 0.25!</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical variance in each Markov chain</span></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>      var <span class="op">=</span> welford_summary(fs)[<span class="dv">1</span>]</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> var <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>        no_zvar_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span> <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: Expectand has vanishing empirical'</span> \</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="st">' variance!</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check split Rhat across Markov chains</span></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>    chains <span class="op">=</span> [ unpermuted_samples[:,c,idx] <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ]</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a>    rhat <span class="op">=</span> compute_split_rhat(chains)</span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> math.isnan(rhat):</span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>      local_message <span class="op">+=</span> <span class="st">'  Split hat</span><span class="sc">{R}</span><span class="st"> is ill-defined!</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> rhat <span class="op">&gt;</span> <span class="fl">1.1</span>:</span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>      no_rhat_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a>      local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>      local_message <span class="op">+=</span> <span class="ss">f'  Split hat</span><span class="ch">{{</span><span class="ss">R</span><span class="ch">}}</span><span class="ss"> (</span><span class="sc">{</span>rhat<span class="sc">:.3f}</span><span class="ss">) exceeds 1.1!</span><span class="ch">\n</span><span class="ss">'</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical integrated autocorrelation time</span></span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a>      fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>      int_ac_time <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (int_ac_time <span class="op">/</span> N) <span class="op">&gt;</span> <span class="fl">0.25</span>:</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>        no_tauhat_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span>  <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: hat</span><span class="ch">{{</span><span class="ss">tau</span><span class="ch">}}</span><span class="ss"> per iteration '</span> \</span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="ss">f'(</span><span class="sc">{</span>int_ac_time <span class="op">/</span> N<span class="sc">:.3f}</span><span class="ss">) exceeds 0.25!</span><span class="ch">\n</span><span class="ss">'</span></span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical effective sample size</span></span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>      neff <span class="op">=</span> N <span class="op">/</span> int_ac_time</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> neff <span class="op">&lt;</span> min_neff_per_chain:</span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>        no_neff_warning <span class="op">=</span> <span class="va">False</span></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>        local_warning <span class="op">=</span> <span class="va">True</span></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>        local_message <span class="op">+=</span>  <span class="ss">f'  Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">: hat</span><span class="ch">{{</span><span class="ss">ESS</span><span class="ch">}}</span><span class="ss"> (</span><span class="sc">{</span>neff<span class="sc">:.1f}</span><span class="ss">) is smaller '</span> \</span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>                        <span class="op">+</span> <span class="ss">f'than desired (</span><span class="sc">{</span>min_neff_per_chain<span class="sc">:.0f}</span><span class="ss">)!</span><span class="ch">\n</span><span class="ss">'</span></span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>    local_message <span class="op">+=</span> <span class="st">'</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> local_warning:</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>      message <span class="op">+=</span> local_message</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_khat_warning:</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>    message <span class="op">+=</span>  <span class="st">'Large tail hat</span><span class="sc">{k}</span><span class="st">s suggest that the expectand'</span> \</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' might not be sufficiently integrable.</span><span class="ch">\n\n</span><span class="st">'</span></span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_zvar_warning:</span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>    message <span class="op">+=</span>  <span class="st">'If the expectands are not constant then zero empirical'</span> \</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' variance suggests that the Markov'</span> \</span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' transitions are misbehaving.</span><span class="ch">\n\n</span><span class="st">'</span></span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_rhat_warning:</span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a>    message <span class="op">+=</span>  <span class="st">'Split hat</span><span class="sc">{R}</span><span class="st"> larger than 1.1 is inconsisent with'</span> \</span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' equilibrium.</span><span class="ch">\n\n</span><span class="st">'</span></span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_tauhat_warning:</span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a>    message <span class="op">+=</span>  <span class="st">'hat</span><span class="sc">{tau}</span><span class="st"> larger than a quarter of the Markov chain'</span> \</span>
<span id="cb23-124"><a href="#cb23-124" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' length suggests that Markov chain Monte Carlo,'</span> \</span>
<span id="cb23-125"><a href="#cb23-125" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' estimates will be unreliable.</span><span class="ch">\n\n</span><span class="st">'</span></span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="kw">not</span> no_neff_warning:</span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a>    message <span class="op">+=</span>  <span class="st">'If hat</span><span class="sc">{ESS}</span><span class="st"> is too small then reliable Markov chain'</span> \</span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">' Monte Carlo estimators may still be too imprecise.</span><span class="ch">\n\n</span><span class="st">'</span></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> no_khat_warning <span class="kw">and</span> no_zvar_warning <span class="kw">and</span> no_rhat_warning <span class="op">\</span></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>     <span class="kw">and</span> no_tauhat_warning <span class="kw">and</span> no_neff_warning:</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a>    message <span class="op">=</span>   <span class="st">'All expectands checked appear to be behaving well enough '</span> \</span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a>              <span class="op">+</span> <span class="st">'for reliable Markov chain Monte Carlo estimation.</span><span class="ch">\n</span><span class="st">'</span></span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(message)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> expectand_diagnostics_summary(fit,</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>                                  expectand_idxs<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                                  min_neff_per_chain<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                                  exclude_zvar<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Summarize expectand diagnostics"""</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  unpermuted_samples <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_samples.shape</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>  I <span class="op">=</span> input_dims[<span class="dv">2</span>]</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> expectand_idxs <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">range</span>(I)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>  bad_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(<span class="bu">range</span>(I))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(bad_idxs) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Excluding the invalid expectand indices: </span><span class="sc">{</span>bad_idxs<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    expectand_idxs <span class="op">=</span> <span class="bu">set</span>(expectand_idxs).difference(bad_idxs)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>  failed_idx <span class="op">=</span> []</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>  failed_khat_idx <span class="op">=</span> []</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>  failed_zvar_idx <span class="op">=</span> []</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>  failed_rhat_idx <span class="op">=</span> []</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>  failed_tauhat_idx <span class="op">=</span> []</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>  failed_neff_idx <span class="op">=</span> []</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> idx <span class="kw">in</span> expectand_idxs:</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> exclude_zvar:</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check zero variance across all Markov chains for exclusion</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>      any_zvar <span class="op">=</span> <span class="va">False</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        var <span class="op">=</span> welford_summary(fs)[<span class="dv">1</span>]</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> var <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>          any_zvar <span class="op">=</span> <span class="va">True</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> any_zvar:</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check tail khats in each Markov chain</span></span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>      fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>      khats <span class="op">=</span> compute_tail_khats(fs)</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> khats[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span> <span class="kw">or</span> khats[<span class="dv">1</span>] <span class="op">&gt;=</span> <span class="fl">0.25</span>:</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        failed_idx.append(idx)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>        failed_khat_idx.append(idx)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical variance in each Markov chain</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>      var <span class="op">=</span> welford_summary(fs)[<span class="dv">1</span>]</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> var <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>        failed_idx.append(idx)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>        failed_zvar_idx.append(idx)</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check split Rhat across Markov chains</span></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>    chains <span class="op">=</span> [ unpermuted_samples[:,c,idx] <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ]</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>    rhat <span class="op">=</span> compute_split_rhat(chains)</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> math.isnan(rhat):</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>      failed_idx.append(idx)</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>      failed_rhat_idx.append(idx)</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> rhat <span class="op">&gt;</span> <span class="fl">1.1</span>:</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>      failed_idx.append(idx)</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>      failed_rhat_idx.append(idx)</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical integrated autocorrelation time</span></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>      fs <span class="op">=</span> unpermuted_samples[:,c,idx]</span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>      int_ac_time <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (int_ac_time <span class="op">/</span> N) <span class="op">&gt;</span> <span class="fl">0.25</span>:</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>        failed_idx.append(idx)</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>        failed_tauhat_idx.append(idx)</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>      <span class="co"># Check empirical effective sample size</span></span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>      neff <span class="op">=</span> N <span class="op">/</span> int_ac_time</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> neff <span class="op">&lt;</span> min_neff_per_chain:</span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>        failed_idx.append(idx)</span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>        failed_neff_idx.append(idx)</span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>  failed_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_idx))</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_idx):</span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered diagnostic warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'All expectands checked appear to be behaving'</span> \</span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">'well enough for Markov chain Monte Carlo estimation.'</span>)</span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a>  failed_khat_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_khat_idx))</span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_khat_idx):</span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_khat_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered hat</span><span class="sc">{k}</span><span class="st"> warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  Large tail hat</span><span class="sc">{k}</span><span class="st">s suggest that the expectand'</span> \</span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' might not be sufficiently integrable.</span><span class="ch">\n\n</span><span class="st">'</span>)</span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a>  failed_zvar_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_zvar_idx))</span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_zvar_idx):</span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_zvar_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered zero variance warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-98"><a href="#cb24-98" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  If the expectands are not constant then zero empirical'</span> \</span>
<span id="cb24-99"><a href="#cb24-99" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' variance suggests that the Markov'</span> \</span>
<span id="cb24-100"><a href="#cb24-100" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' transitions are misbehaving.</span><span class="ch">\n\n</span><span class="st">'</span>)</span>
<span id="cb24-101"><a href="#cb24-101" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-102"><a href="#cb24-102" aria-hidden="true" tabindex="-1"></a>  failed_rhat_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_rhat_idx))</span>
<span id="cb24-103"><a href="#cb24-103" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_rhat_idx):</span>
<span id="cb24-104"><a href="#cb24-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_rhat_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-105"><a href="#cb24-105" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered hat</span><span class="sc">{R}</span><span class="st"> warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-106"><a href="#cb24-106" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  Split hat</span><span class="sc">{R}</span><span class="st"> larger than 1.1 is inconsistent with'</span> \</span>
<span id="cb24-107"><a href="#cb24-107" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' equilibrium.</span><span class="ch">\n\n</span><span class="st">'</span>)</span>
<span id="cb24-108"><a href="#cb24-108" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-109"><a href="#cb24-109" aria-hidden="true" tabindex="-1"></a>  failed_tauhat_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_tauhat_idx))</span>
<span id="cb24-110"><a href="#cb24-110" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_tauhat_idx):</span>
<span id="cb24-111"><a href="#cb24-111" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_tauhat_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-112"><a href="#cb24-112" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered hat</span><span class="sc">{tau}</span><span class="st"> warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-113"><a href="#cb24-113" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  hat</span><span class="sc">{tau}</span><span class="st"> larger than a quarter of the Markov chain'</span> \</span>
<span id="cb24-114"><a href="#cb24-114" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' length suggests that Markov chain Monte Carlo'</span> \</span>
<span id="cb24-115"><a href="#cb24-115" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' estimates may be unreliable.</span><span class="ch">\n\n</span><span class="st">'</span>)</span>
<span id="cb24-116"><a href="#cb24-116" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb24-117"><a href="#cb24-117" aria-hidden="true" tabindex="-1"></a>  failed_neff_idx <span class="op">=</span> <span class="bu">list</span>(numpy.unique(failed_neff_idx))</span>
<span id="cb24-118"><a href="#cb24-118" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(failed_neff_idx):</span>
<span id="cb24-119"><a href="#cb24-119" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f'The expectands </span><span class="sc">{</span><span class="bu">str</span>(failed_neff_idx)<span class="sc">.</span>replace(<span class="st">"["</span>, <span class="st">""</span>)<span class="sc">.</span>replace(<span class="st">"]"</span>, <span class="st">""</span>)<span class="sc">}</span><span class="ss">'</span> \</span>
<span id="cb24-120"><a href="#cb24-120" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' triggered hat</span><span class="sc">{ESS}</span><span class="st"> warnings.</span><span class="ch">\n</span><span class="st">'</span>)</span>
<span id="cb24-121"><a href="#cb24-121" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(  <span class="st">'  If hat</span><span class="sc">{ESS}</span><span class="st"> is too small then even reliable Markov chain'</span> \</span>
<span id="cb24-122"><a href="#cb24-122" aria-hidden="true" tabindex="-1"></a>          <span class="op">+</span> <span class="st">' Monte Carlo estimators may still be too imprecise.</span><span class="ch">\n\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="empirical-autocorrelation-visualization" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="empirical-autocorrelation-visualization"><span class="header-section-number">2.6</span> Empirical Autocorrelation Visualization</h2>
<p>If we encounter large empirical integrated autocorrelation times, or small estimated effective sample sizes, then we may want to follow up with the empirical autocorrelations themselves. An empirical correlogram provides a useful visualization of these estimates.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_rhos(fs):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Visualize empirical autocorrelations for a given sequence"""</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute empirical autocorrelations</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(fs)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  m, v <span class="op">=</span> welford_summary(fs)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  zs <span class="op">=</span> [ f <span class="op">-</span> m <span class="cf">for</span> f <span class="kw">in</span> fs ]</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> v <span class="op">&lt;</span> <span class="fl">1e-10</span>:</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [<span class="dv">1</span>] <span class="op">*</span> N</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>  B <span class="op">=</span> <span class="dv">2</span><span class="op">**</span>math.ceil(math.log2(N)) <span class="co"># Next power of 2 after N</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>  zs_buff <span class="op">=</span> zs <span class="op">+</span> [<span class="dv">0</span>] <span class="op">*</span> (B <span class="op">-</span> N)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>  Fs <span class="op">=</span> numpy.fft.fft(zs_buff)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>  Ss <span class="op">=</span> numpy.<span class="bu">abs</span>(Fs)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>  Rs <span class="op">=</span> numpy.fft.ifft(Ss)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>  acov_buff <span class="op">=</span> numpy.real(Rs)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>  rhos <span class="op">=</span> acov_buff[<span class="dv">0</span>:N] <span class="op">/</span> acov_buff[<span class="dv">0</span>]</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Drop last lag if (L + 1) is odd so that the lag pairs are complete</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>  L <span class="op">=</span> N</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (L <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> L <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Number of lag pairs</span></span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>  P <span class="op">=</span> (L <span class="op">+</span> <span class="dv">1</span>) <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Construct asymptotic correlation from initial monotone sequence</span></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>  old_pair_sum <span class="op">=</span> rhos[<span class="dv">1</span>] <span class="op">+</span> rhos[<span class="dv">2</span>]</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>  max_L <span class="op">=</span> N</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> p <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, P):</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    current_pair_sum <span class="op">=</span> rhos[<span class="dv">2</span> <span class="op">*</span> p] <span class="op">+</span> rhos[<span class="dv">2</span> <span class="op">*</span> p <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_pair_sum <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>      max_L <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> p</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>      rhos[max_L:N] <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> (N <span class="op">-</span> max_L)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>      <span class="cf">break</span></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_pair_sum <span class="op">&gt;</span> old_pair_sum:</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>      current_pair_sum <span class="op">=</span> old_pair_sum</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>      rhos[<span class="dv">2</span> <span class="op">*</span> p]     <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> old_pair_sum</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>      rhos[<span class="dv">2</span> <span class="op">*</span> p <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> old_pair_sum</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if p == P:</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>      <span class="co"># throw some kind of error when autocorrelation</span></span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>      <span class="co"># sequence doesn't get terminated</span></span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>    old_pair_sum <span class="op">=</span> current_pair_sum</span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> rhos</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_empirical_correlogram(ax,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                               unpermuted_fs,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>                               max_L,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                               rholim<span class="op">=</span>[<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">1.1</span>],</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                               name<span class="op">=</span><span class="st">""</span>):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Plot empirical correlograms for the expectand output ensembels in a</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">     collection of Markov chains"""</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  idxs <span class="op">=</span> [ idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(max_L) <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>) ]</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>  xs <span class="op">=</span> [ idx <span class="op">+</span> delta <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(max_L) <span class="cf">for</span> delta <span class="kw">in</span> [<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>]]</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>  colors <span class="op">=</span> [dark, dark_highlight, mid, light_highlight]</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> (unpermuted_samples.shape)[<span class="dv">1</span>]</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    fs <span class="op">=</span> unpermuted_fs[:,c]</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    rhos <span class="op">=</span> compute_rhos(fs)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    pad_rhos <span class="op">=</span> [ rhos[idx] <span class="cf">for</span> idx <span class="kw">in</span> idxs ]</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    ax.plot(xs, pad_rhos, colors[c <span class="op">%</span> <span class="dv">4</span>], linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>  ax.axhline(y<span class="op">=</span><span class="dv">0</span>, linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">"#DDDDDD"</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>  ax.set_title(name)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(<span class="st">"Lag"</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>  ax.set_xlim(<span class="op">-</span><span class="fl">0.5</span>, max_L <span class="op">+</span> <span class="fl">0.5</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="st">"Empirical</span><span class="ch">\n</span><span class="st">Autocorrelation"</span>)</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>  ax.set_ylim(rholim[<span class="dv">0</span>], rholim[<span class="dv">1</span>])</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>  ax.spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>  ax.spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="chain-separated-pairs-plot" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="chain-separated-pairs-plot"><span class="header-section-number">2.7</span> Chain-Separated Pairs Plot</h2>
<p>We can also visualize strong autocorrelations by coloring the states of each Markov chain in a continuous gradient. When neighboring states are strongly correlated these colors will appear to vary smoothly across the ambient space. More productive Markov transitions result in a more chaotic spray of colors.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_chain_sep_pairs(unpermuted_f1s, name_x,</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>                         unpermuted_f2s, name_y):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Plot two expectand output ensembles againt each other separated by</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">     Markov chain """</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  input_dims <span class="op">=</span> unpermuted_f1s.shape</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> input_dims[<span class="dv">0</span>]</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> input_dims[<span class="dv">1</span>]</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  colors <span class="op">=</span> [<span class="st">"#DCBCBC"</span>, <span class="st">"#C79999"</span>, <span class="st">"#B97C7C"</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">"#A25050"</span>, <span class="st">"#8F2727"</span>, <span class="st">"#7C0000"</span>]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>  cmap <span class="op">=</span> LinearSegmentedColormap.from_list(<span class="st">"reds"</span>, colors, N<span class="op">=</span>N)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  min_x <span class="op">=</span> <span class="bu">min</span>([ <span class="bu">min</span>(unpermuted_f1s[:,c]) <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ])</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  max_x <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(unpermuted_f1s[:,c]) <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ])</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  min_y <span class="op">=</span> <span class="bu">min</span>([ <span class="bu">min</span>(unpermuted_f2s[:,c]) <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ])</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>  max_y <span class="op">=</span> <span class="bu">max</span>([ <span class="bu">max</span>(unpermuted_f2s[:,c]) <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ])</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  N_plots <span class="op">=</span> C</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>  N_cols <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  N_rows <span class="op">=</span> math.ceil(N_plots <span class="op">/</span> N_cols)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>  f, axarr <span class="op">=</span> plot.subplots(N_rows, N_cols)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>  k <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    idx1 <span class="op">=</span> k <span class="op">//</span> N_cols</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    idx2 <span class="op">=</span> k <span class="op">%</span> N_cols</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    k <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].scatter(unpermuted_f1s.flatten(), </span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>                              unpermuted_f2s.flatten(),</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>                              color<span class="op">=</span><span class="st">"#DDDDDD"</span>, s<span class="op">=</span><span class="dv">10</span>, zorder<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].scatter(unpermuted_f1s[:,c], unpermuted_f2s[:,c],</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>                              cmap<span class="op">=</span>cmap, c<span class="op">=</span><span class="bu">range</span>(N), s<span class="op">=</span><span class="dv">10</span>, zorder<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_title(<span class="ss">f'Chain </span><span class="sc">{</span>c <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlabel(name_x)</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_xlim([min_x, max_x])</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylabel(name_y)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].set_ylim([min_y, max_y])</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    axarr[idx1, idx2].spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>  plot.subplots_adjust(hspace<span class="op">=</span><span class="fl">1.0</span>, wspace<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>  plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="markov-chain-monte-carlo-estimation" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Markov chain Monte Carlo Estimation</h1>
<p>If none of the diagnostics indicate an obstruction to a Markov chain Monte Carlo central limit theorem then we can construct expectation value estimates and their standard errors.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pushforward_chains(chains, expectand):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Evaluate an expectand along a Markov chain"""</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [ [ expectand(x) <span class="cf">for</span> x <span class="kw">in</span> chain ] <span class="cf">for</span> chain <span class="kw">in</span> chains ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mcmc_est(fs):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Estimate expectand expectation value from a Markov chain"""</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  N <span class="op">=</span> <span class="bu">len</span>(fs)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> N <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [fs[<span class="dv">0</span>], <span class="dv">0</span>, math.nan]</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  summary <span class="op">=</span> welford_summary(fs)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> summary[<span class="dv">1</span>] <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [summary[<span class="dv">0</span>], <span class="dv">0</span>, math.nan]</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  int_ac_time <span class="op">=</span> compute_tauhat(fs)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>  neff <span class="op">=</span> N <span class="op">/</span> int_ac_time</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [summary[<span class="dv">0</span>], math.sqrt(summary[<span class="dv">1</span>] <span class="op">/</span> neff), neff]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ensemble_mcmc_est(chains):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Estimate expectand exectation value from a collection of Markov chains"""</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> <span class="bu">len</span>(chains)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  chain_ests <span class="op">=</span> [ mcmc_est(chain) <span class="cf">for</span> chain <span class="kw">in</span> chains ]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Total effective sample size</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  total_ess <span class="op">=</span> <span class="bu">sum</span>([ est[<span class="dv">2</span>] <span class="cf">for</span> est <span class="kw">in</span> chain_ests ])</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> math.isnan(total_ess):</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    m  <span class="op">=</span> numpy.mean([ est[<span class="dv">0</span>] <span class="cf">for</span> est <span class="kw">in</span> chain_ests ])</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> numpy.mean([ est[<span class="dv">1</span>] <span class="cf">for</span> est <span class="kw">in</span> chain_ests ])</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [m, se, math.nan]</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ensemble average weighted by effective sample size</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>  mean <span class="op">=</span> <span class="bu">sum</span>([ est[<span class="dv">0</span>] <span class="op">*</span> est[<span class="dv">2</span>] <span class="cf">for</span> est <span class="kw">in</span> chain_ests ]) <span class="op">/</span> total_ess</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Ensemble variance weighed by effective sample size</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># including correction for the fact that individual Markov chain</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># variances are defined relative to the individual mean estimators</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># and not the ensemble mean estimator</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>  <span class="bu">vars</span> <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> C</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C):</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    est <span class="op">=</span> chain_ests[c]</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    chain_var <span class="op">=</span> est[<span class="dv">2</span>] <span class="op">*</span> est[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    var_update <span class="op">=</span> (est[<span class="dv">0</span>] <span class="op">-</span> mean)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">vars</span>[c] <span class="op">=</span> est[<span class="dv">2</span>] <span class="op">*</span> (var_update <span class="op">+</span> chain_var)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>  var <span class="op">=</span> <span class="bu">sum</span>(<span class="bu">vars</span>) <span class="op">/</span> total_ess</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [mean, math.sqrt(var <span class="op">/</span> total_ess), total_ess]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In addition to examining the single expectation value of an expectand we can also visualize the entire pushforward distribution of the expectand by estimating the target probabilities in histogram bins.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_pushforward_hist(ax, unpermuted_samples, B, flim<span class="op">=</span><span class="va">None</span>, name<span class="op">=</span><span class="st">"f"</span>):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Plot pushforward histogram of a given expectand using Markov chain</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">     Monte Carlo estimators to estimate the output bin probabilities"""</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> flim <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Automatically adjust histogram binning to range of outputs</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    min_f <span class="op">=</span> <span class="bu">min</span>(unpermuted_samples.flatten())</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    max_f <span class="op">=</span> <span class="bu">max</span>(unpermuted_samples.flatten())</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add bounding bins</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    delta <span class="op">=</span> (max_f <span class="op">-</span> min_f) <span class="op">/</span> B</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    min_f <span class="op">=</span> min_f <span class="op">-</span> delta</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    max_f <span class="op">=</span> max_f <span class="op">+</span> delta</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    flim <span class="op">=</span> [min_f, max_f]</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    bins <span class="op">=</span> numpy.arange(min_f, max_f <span class="op">+</span> delta, delta)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> B <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    delta <span class="op">=</span> (flim[<span class="dv">1</span>] <span class="op">-</span> flim[<span class="dv">0</span>]) <span class="op">/</span> B</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    bins <span class="op">=</span> numpy.arange(flim[<span class="dv">0</span>], flim[<span class="dv">1</span>] <span class="op">+</span> delta, delta)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>  mean_p <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> B</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>  delta_p <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> B</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>  C <span class="op">=</span> (unpermuted_samples.shape)[<span class="dv">1</span>]</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>  chains <span class="op">=</span> [ unpermuted_samples[:,c] <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(C) ]</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> bin_indicator(x):</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="fl">1.0</span> <span class="cf">if</span> bins[b] <span class="op">&lt;=</span> x <span class="kw">and</span> x <span class="op">&lt;</span> bins[b <span class="op">+</span> <span class="dv">1</span>] <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    indicator_chains <span class="op">=</span> pushforward_chains(chains, bin_indicator)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    est <span class="op">=</span> ensemble_mcmc_est(indicator_chains)</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize bin probabilities by bin width to allow</span></span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># for direct comparison to probability density functions</span></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> bins[b <span class="op">+</span> <span class="dv">1</span>] <span class="op">-</span> bins[b]</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>    mean_p[b] <span class="op">=</span> est[<span class="dv">0</span>] <span class="op">/</span> width</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    delta_p[b] <span class="op">=</span> est[<span class="dv">1</span>] <span class="op">/</span> width</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>  idxs <span class="op">=</span> [ idx <span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(B) <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>) ]</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>  xs <span class="op">=</span> [ bins[b <span class="op">+</span> o] <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(B) <span class="cf">for</span> o <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>) ]</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>  lower_inter <span class="op">=</span> [ <span class="bu">max</span>(mean_p[idx] <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> delta_p[idx], <span class="dv">0</span>)         <span class="cf">for</span> idx <span class="kw">in</span> idxs ]</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>  upper_inter <span class="op">=</span> [ <span class="bu">min</span>(mean_p[idx] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> delta_p[idx], <span class="dv">1</span> <span class="op">/</span> width) <span class="cf">for</span> idx <span class="kw">in</span> idxs ]</span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>  min_y <span class="op">=</span>        <span class="bu">min</span>(lower_inter)</span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>  max_y <span class="op">=</span> <span class="fl">1.05</span> <span class="op">*</span> <span class="bu">max</span>(upper_inter)</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>  ax.fill_between(xs, lower_inter, upper_inter,</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>                    facecolor<span class="op">=</span>light, color<span class="op">=</span>light)</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>  ax.plot(xs, [ mean_p[idx] <span class="cf">for</span> idx <span class="kw">in</span> idxs ], color<span class="op">=</span>dark, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>  ax.set_xlim(flim)</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>  ax.set_xlabel(name)</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>  ax.set_ylim([min_y, max_y])</span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>  ax.set_ylabel(<span class="st">"Estimated Bin</span><span class="ch">\n</span><span class="st">Probabilities"</span>)</span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>  ax.get_yaxis().set_visible(<span class="va">False</span>)</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>  ax.spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>  ax.spines[<span class="st">"left"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>  ax.spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="demonstration" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Demonstration</h1>
<p>Now let’s put all of these analysis tools to use with an <code>pystan</code> fit object.</p>
<p>First we can simulate some binary data from a logistic regression model.</p>
<!--



```{stan}
#| file: "stan_programs/simu_logistic_reg.stan"
#| eval: FALSE
#| output.var: ""
#| filename: "simu_logistic_reg.stan"
```



-->
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'stan_programs/simu_logistic_reg.stan'</span>, <span class="st">'r'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  lines <span class="op">=</span> <span class="bu">file</span>.readlines()[<span class="dv">0</span>:<span class="dv">4</span>]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> line <span class="kw">in</span> lines:</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(line),</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>transformed data {

  int&lt;lower=0&gt; M = 3;         // Number of covariates

  int&lt;lower=0&gt; N = 1000;      // Number of observations

  
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> compile_model(<span class="st">'stan_programs/simu_logistic_reg.stan'</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>simu <span class="op">=</span> model.sampling(<span class="bu">iter</span><span class="op">=</span><span class="dv">1</span>, warmup<span class="op">=</span><span class="dv">0</span>, chains<span class="op">=</span><span class="dv">1</span>, chain_id<span class="op">=</span>[<span class="dv">1</span>],</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                      refresh<span class="op">=</span><span class="dv">1000</span>, seed<span class="op">=</span><span class="dv">4838282</span>, algorithm<span class="op">=</span><span class="st">"Fixed_param"</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> simu.extract()[<span class="st">'X'</span>][<span class="dv">0</span>]</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> simu.extract()[<span class="st">'y'</span>][<span class="dv">0</span>].astype(numpy.int64)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> <span class="bu">dict</span>(M <span class="op">=</span> <span class="dv">3</span>, N <span class="op">=</span> <span class="dv">1000</span>, x0 <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], X <span class="op">=</span> X, y <span class="op">=</span> y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using cached StanModel
Iteration: 1 / 1 [100%]  (Sampling)

 Elapsed Time: 0 seconds (Warm-up)
               0.001805 seconds (Sampling)
               0.001805 seconds (Total)
</code></pre>
</div>
</div>
<p>We’ll try to fit this model not with a constraint-respecting logistic regression model but rather a constraint blaspheming linear probability model. Importantly the resulting posterior density function is discontinuous with configurations <code>alpha + deltaX * beta &gt; 0</code> resulting in finite <code>bernoulli_lpmf</code> outputs and those with <code>alpha + deltaX * beta &lt;= 0</code> resulting in minus infinite outputs.</p>
<!--



```{stan}
#| file: "stan_programs/bernoulli_linear.stan"
#| eval: FALSE
#| output.var: ""
#| filename: "bernoulli_linear.stan"
```



-->
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'stan_programs/bernoulli_linear.stan'</span>, <span class="st">'r'</span>) <span class="im">as</span> <span class="bu">file</span>:</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  lines <span class="op">=</span> <span class="bu">file</span>.readlines()[<span class="dv">0</span>:<span class="dv">4</span>]</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> line <span class="kw">in</span> lines:</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(line),</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>data {

  int&lt;lower=0&gt; M; // Number of covariates

  int&lt;lower=0&gt; N; // Number of observations

  
</code></pre>
</div>
</div>
<p>Because of this awkward constraint we have to carefully initialize our Markov chains to satisfy the <code>alpha + deltaX * beta &gt; 0</code> constraint.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>numpy.random.seed(seed<span class="op">=</span><span class="dv">48383499</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>interval_inits <span class="op">=</span> [<span class="va">None</span>] <span class="op">*</span> <span class="dv">4</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  beta <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  alpha <span class="op">=</span> stats.norm.rvs(<span class="fl">0.5</span>, <span class="fl">0.1</span>, size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  interval_inits[c] <span class="op">=</span> <span class="bu">dict</span>(alpha <span class="op">=</span> alpha, beta <span class="op">=</span> beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> compile_model(<span class="st">'stan_programs/bernoulli_linear.stan'</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>fit <span class="op">=</span> model.sampling(data<span class="op">=</span>data, seed<span class="op">=</span><span class="dv">8438338</span>, warmup<span class="op">=</span><span class="dv">1000</span>, <span class="bu">iter</span><span class="op">=</span><span class="dv">2024</span>,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>                     chain_id<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], refresh<span class="op">=</span><span class="dv">0</span>, init<span class="op">=</span>interval_inits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using cached StanModel</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Gradient evaluation took 0.000253 seconds
1000 transitions using 10 leapfrog steps per transition would take 2.53 seconds.
Adjust your expectations accordingly!



Gradient evaluation took 0.000238 seconds
1000 transitions using 10 leapfrog steps per transition would take 2.38 seconds.
Adjust your expectations accordingly!



Gradient evaluation took 0.00021 seconds
1000 transitions using 10 leapfrog steps per transition would take 2.1 seconds.
Adjust your expectations accordingly!



Gradient evaluation took 0.000208 seconds
1000 transitions using 10 leapfrog steps per transition would take 2.08 seconds.
Adjust your expectations accordingly!

</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 Elapsed Time: 0.675333 seconds (Warm-up)
               0.511162 seconds (Sampling)
               1.18649 seconds (Total)


 Elapsed Time: 0.768039 seconds (Warm-up)
               0.538958 seconds (Sampling)
               1.307 seconds (Total)
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 Elapsed Time: 0.819684 seconds (Warm-up)
               0.58328 seconds (Sampling)
               1.40296 seconds (Total)
</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
 Elapsed Time: 0.801247 seconds (Warm-up)
               3.52494 seconds (Sampling)
               4.32619 seconds (Total)
</code></pre>
</div>
</div>
<p>Stan is able to run to completion, but just how useful are the Markov chains that it generates?</p>
<p>Let’s start with the Hamiltonian Monte Carlo diagnostics.</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>check_all_hmc_diagnostics(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4056 of 4096 iterations ended with a divergence (99.02%)
  Divergences are due unstable numerical integration.
  These instabilities are often due to posterior degeneracies.
  If there are only a small number of divergences then running
with adapt_delta larger than 0.801 may reduce the
divergences at the cost of more expensive transitions.

Chain 3: Average proxy acceptance statistic (0.716)
         is smaller than 90% of the target (0.801)
  A small average proxy acceptance statistic indicates that the
integrator step size adaptation failed to converge.  This is often
due to discontinuous or inexact gradients.

</code></pre>
</div>
</div>
<p>Almost every transition across the four Markov chains resulted in a divergence. This is due to the discontinuity in the linear probability model as the sudden jump from a finite to a negative infinite target density results in unstable numerical trajectories.</p>
<p>We also see the one of the Markov chains wasn’t quite able to hit the step size adaptation target. To see why let’s dig into the adapted configuration of the Hamiltonian Markov transition.</p>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>plot_inv_metric(fit, <span class="dv">75</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-39-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The step size in the third Markov chain is slightly larger than the others which explains the lower average proxy acceptance statistic. We can also see that the first Markov chain has a much smaller step size than the other which results in an overly conservative average proxy acceptance statistic.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>display_stepsizes(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: Integrator Step Size = 5.35e-03
Chain 2: Integrator Step Size = 3.23e-02
Chain 3: Integrator Step Size = 4.70e-02
Chain 4: Integrator Step Size = 4.08e-02</code></pre>
</div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>display_ave_accept_proxy(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: Average proxy acceptance statistic = 0.968
Chain 2: Average proxy acceptance statistic = 0.760
Chain 3: Average proxy acceptance statistic = 0.716
Chain 4: Average proxy acceptance statistic = 0.737</code></pre>
</div>
</div>
<p>That one Markov chain with the smaller adapted step size requires much longer, and more expensive, numerical trajectories, than than the other three Markov chains in order to attain the same exploration.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>plot_num_leapfrog(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-42-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Finally because nearly every transition is divergent we can’t extract much information from the divergent-labeled pairs plots.</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>plot_div_pairs(fit,</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>               [<span class="st">"alpha"</span>, <span class="st">"beta[1]"</span>, <span class="st">"beta[2]"</span>, <span class="st">"beta[3]"</span>],</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>               [<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-43-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Having examined the Hamiltonian Monte Carlo diagnostics let’s now look through the expectand specific diagnostics. By default we’ll look at the parameter projection functions as well as all of the expectands defined in the <code>generated quantities</code> block.</p>
<p>Because of the Hamiltonian Monte Carlo diagnostic failures let’s start by looking at the expectand diagnostics summary instead of the full details.</p>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>expectand_diagnostics_summary(fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>The expectands 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 2004 triggered diagnostic warnings.

The expectands 803 triggered hat{k} warnings.

  Large tail hat{k}s suggest that the expectand might not be sufficiently integrable.


The expectands 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 319, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 401, 402, 404, 405, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 629, 630, 632, 633, 634, 635, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 870, 871, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 2004 triggered hat{R} warnings.

  Split hat{R} larger than 1.1 is inconsistent with equilibrium.


The expectands 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 2004 triggered hat{ESS} warnings.

  If hat{ESS} is too small then even reliable Markov chain Monte Carlo estimators may still be too imprecise.

</code></pre>
</div>
</div>
<p>That is a lot of diagnostic failures. To avoid overwhelming ourselves with too many detailed diagnosic messages let’s focus on the four parameter expectands.</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>check_all_expectand_diagnostics(fit, <span class="bu">range</span>(<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>alpha:
  Split hat{R} (1.600) exceeds 1.1!
  Chain 1: hat{ESS} (5.8) is smaller than desired (100)!
  Chain 2: hat{ESS} (14.9) is smaller than desired (100)!
  Chain 3: hat{ESS} (9.9) is smaller than desired (100)!
  Chain 4: hat{ESS} (7.4) is smaller than desired (100)!

beta[1]:
  Split hat{R} (1.646) exceeds 1.1!
  Chain 1: hat{ESS} (5.6) is smaller than desired (100)!
  Chain 2: hat{ESS} (6.0) is smaller than desired (100)!
  Chain 3: hat{ESS} (5.6) is smaller than desired (100)!
  Chain 4: hat{ESS} (5.6) is smaller than desired (100)!

beta[2]:
  Split hat{R} (1.163) exceeds 1.1!
  Chain 1: hat{ESS} (8.1) is smaller than desired (100)!
  Chain 2: hat{ESS} (8.3) is smaller than desired (100)!
  Chain 3: hat{ESS} (7.1) is smaller than desired (100)!
  Chain 4: hat{ESS} (7.2) is smaller than desired (100)!

beta[3]:
  Split hat{R} (1.731) exceeds 1.1!
  Chain 1: hat{ESS} (5.4) is smaller than desired (100)!
  Chain 2: hat{ESS} (8.1) is smaller than desired (100)!
  Chain 3: hat{ESS} (6.5) is smaller than desired (100)!
  Chain 4: hat{ESS} (4.9) is smaller than desired (100)!

Split hat{R} larger than 1.1 is inconsisent with equilibrium.

If hat{ESS} is too small then reliable Markov chain Monte Carlo estimators may still be too imprecise.

</code></pre>
</div>
</div>
<p>All four parameter expectands exhibit split <span class="math inline">\hat{R}</span> warnings and low empirical effective sample size warnings. The question is whether or not the split <span class="math inline">\hat{R}</span> warnings indicate quasistationarity or just insufficient exploration.</p>
<p>Motivated by the small effective sample size estimates let’s look at the empirical correlograms for each parameter expectand.</p>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>unpermuted_samples <span class="op">=</span> fit.extract(permuted<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>f, axarr <span class="op">=</span> plot.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>plot_empirical_correlogram(axarr[<span class="dv">0</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">0</span>], </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                           <span class="dv">300</span>, [<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>], <span class="st">"alpha"</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>plot_empirical_correlogram(axarr[<span class="dv">0</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">1</span>], </span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>                           <span class="dv">300</span>, [<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>], <span class="st">"beta[1]"</span>)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>plot_empirical_correlogram(axarr[<span class="dv">1</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">2</span>], </span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>                           <span class="dv">300</span>, [<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>], <span class="st">"beta[2]"</span>)</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>plot_empirical_correlogram(axarr[<span class="dv">1</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">3</span>], </span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>                           <span class="dv">300</span>, [<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>], <span class="st">"beta[3]"</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>plot.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.5</span>, hspace<span class="op">=</span><span class="fl">0.75</span>)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-46-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Regardless of whether or not these Markov chains are stationary they are extremely autocorrelated. Even assuming stationarity we wouldn’t start to forget the beginning of each Markov chain until we’ve worked through a quarter of the total length, leaving only about four independent samples across each chain.</p>
<p>This is consistent with the constraint violations breaking the coherent, gradient-driven exploration of Hamiltonian Monte Carlo so that the Markov chains devolve into diffuse random walks. Indeed looking at the chain-separated pairs plots we see the spatial color continuity characteristic of a random walk.</p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>plot_chain_sep_pairs(unpermuted_samples[:,:,<span class="dv">0</span>], <span class="st">"alpha"</span>, </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>                     unpermuted_samples[:,:,<span class="dv">1</span>], <span class="st">"beta[1]"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-47-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>To more quantitatively blame the large split <span class="math inline">\hat{R}</span>s on these strong autocorrelations we can plot the split <span class="math inline">\hat{R}</span> from each expectand against the corresponding empirical integrated autocorrelation time across. Specifically for each expectand we plot split <span class="math inline">\hat{R}</span> against we use the smallest empirical integrated autocorrelation of the four Markov chains.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>rhats <span class="op">=</span> compute_split_rhats(fit)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>min_tauhats <span class="op">=</span> compute_min_tauhat(fit)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>plot.scatter(rhats, [ math.log(y) <span class="cf">for</span> y <span class="kw">in</span> min_tauhats ], color<span class="op">=</span>dark, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>plot.gca().set_xlim([<span class="fl">0.95</span>, <span class="dv">2</span>])</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>plot.gca().set_xlabel(<span class="st">"Split Rhat"</span>)</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>plot.gca().set_ylim([<span class="op">-</span><span class="fl">0.75</span>, <span class="dv">5</span>])</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>plot.gca().set_ylabel(<span class="st">"Minimum Empirical</span><span class="ch">\n</span><span class="st">Integrated Autocorrelation Time"</span>)</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>plot.gca().spines[<span class="st">"top"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>plot.gca().spines[<span class="st">"right"</span>].set_visible(<span class="va">False</span>)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-48-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Every expectand with a large split <span class="math inline">\hat{R}</span>s also exhibits a large value the minimum empirical integrated autocorrelation time, confirming that the latter are due to our Markov chains not containing enough information.</p>
<p>If we are sloppy, ignore these diagnostics, and assume that all of our Markov chain Monte Carlo estimators are accurate then we are quickly mislead about the actual behavior of the posterior distribution. One way to guard against this sloppiness is to always accompany a Markov chain Monte Carlo estimator with an estimated error. Even if that error is inaccurate it can sometimes communicate underlying problems.</p>
<p>For example let’s look at a pushforward histogram for each parameter with light red bands visualizing the standard error around the bin probability estimates in dark red.</p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>f, axarr <span class="op">=</span> plot.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">0</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">0</span>], <span class="dv">25</span>, name<span class="op">=</span><span class="st">"alpha"</span>)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">0</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">1</span>], <span class="dv">25</span>, name<span class="op">=</span><span class="st">"beta[1]"</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">1</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">2</span>], <span class="dv">25</span>, name<span class="op">=</span><span class="st">"beta[2]"</span>)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">1</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">3</span>], <span class="dv">25</span>, name<span class="op">=</span><span class="st">"beta[3]"</span>)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>plot.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.1</span>, hspace<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-49-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>If we look at the central estimates alone we might convince ourselves of all kinds of interesting structure. For example potential multi-modality in <code>alpha</code> and <code>beta[2]</code> and platykurticity in <code>beta[1]</code> and <code>beta[3]</code>. These structures, however, are all within the scope of the relatively large standard error bands which suggests that they are all consistent with estimator noise.</p>
<p>Reducing the number of bins decreases the relative standard errors but at the same time many of the visual artifacts recede.</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>f, axarr <span class="op">=</span> plot.subplots(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">0</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">0</span>], <span class="dv">10</span>, name<span class="op">=</span><span class="st">"alpha"</span>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">0</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">1</span>], <span class="dv">10</span>, name<span class="op">=</span><span class="st">"beta[1]"</span>)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">1</span>, <span class="dv">0</span>], unpermuted_samples[:,:,<span class="dv">2</span>], <span class="dv">10</span>, name<span class="op">=</span><span class="st">"beta[2]"</span>)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>plot_pushforward_hist(axarr[<span class="dv">1</span>, <span class="dv">1</span>], unpermuted_samples[:,:,<span class="dv">3</span>], <span class="dv">10</span>, name<span class="op">=</span><span class="st">"beta[3]"</span>)</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>plot.subplots_adjust(wspace<span class="op">=</span><span class="fl">0.1</span>, hspace<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>plot.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="mcmc_diagnostics_pystan2_files/figure-html/cell-50-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>When the bin indicator functions enjoy Markov chain Monte Carlo central limit theorems these standard error bands allow us to discriminate between meaningful structure and accidental artifacts regardless of the histogram binning. Even if central limit theorems don’t hold the error bands provide one more way that we can potentially diagnose untrustworthy computation.</p>
</section>
<section id="license" class="level1 unnumbered">
<h1 class="unnumbered">License</h1>
<p>The code in this case study is copyrighted by Michael Betancourt and licensed under the new BSD (3-clause) license:</p>
<p>https://opensource.org/licenses/BSD-3-Clause</p>
<p>The text and figures in this case study are copyrighted by Michael Betancourt and licensed under the CC BY-NC 4.0 license:</p>
<p>https://creativecommons.org/licenses/by-nc/4.0/</p>
</section>
<section id="original-computing-environment" class="level1 unnumbered">
<h1 class="unnumbered">Original Computing Environment</h1>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> watermark <span class="im">import</span> watermark</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(watermark())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Last updated: 2022-11-26T23:40:08.042016-05:00

Python implementation: CPython
Python version       : 3.9.6
IPython version      : 8.3.0

Compiler    : Clang 12.0.0 (clang-1200.0.32.29)
OS          : Darwin
Release     : 19.6.0
Machine     : x86_64
Processor   : i386
CPU cores   : 16
Architecture: 64bit
</code></pre>
</div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(watermark(packages<span class="op">=</span><span class="st">"matplotlib,numpy,pystan"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>matplotlib: 3.5.2
numpy     : 1.22.3
pystan    : 2.19.1.1
</code></pre>
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>